{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad15d0b1",
   "metadata": {},
   "source": [
    "#### augmentation for the Unet structure. Applied in the LM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd74962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the status of GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "\n",
    "[print(x) for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13b977-9e5e-4f04-8a89-130944b797a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define if the documenting process should go on\n",
    "\n",
    "DOCUMENT = True\n",
    "TRAIN = 5 # training epochs num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f323dfe-e77b-4ea6-a0d6-ffd7287ed0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune document\n",
    "\n",
    "import neptune.new as neptune\n",
    "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "if DOCUMENT:\n",
    "\n",
    "    # run = neptune.init(\n",
    "    #     project=\"leeleeroy/LM-2D-Unet\",\n",
    "    #     api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3YjVjOGVmZi04MjA4LTQ4N2QtOWIzYy05M2YyZWI1NzY3MmEifQ==\",\n",
    "    #     name = \"UNet2D_64_vanilla\",\n",
    "    # ) # necessary credentials, the name could be used to reproduce the results \n",
    "\n",
    "    run = neptune.init(\n",
    "        project=\"leeleeroy/digitalConfocal-zebrafish\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI3YjVjOGVmZi04MjA4LTQ4N2QtOWIzYy05M2YyZWI1NzY3MmEifQ==\",\n",
    "        name = \"UNet2D_256_vanilla\",\n",
    "    )\n",
    "    \n",
    "    # for callbacks in training\n",
    "\n",
    "\n",
    "\n",
    "    neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')  # neptune for the training process\n",
    "    \n",
    "    # neptune document the hyper param.\n",
    "\n",
    "    PARAMS = {\n",
    "              \"optimizer\": {\"learning_rate\": 0.001, \"beta_1\":0.9,\"optimizer\": \"Adam\"},\n",
    "              'epochs': TRAIN,\n",
    "              'batch_size':8}\n",
    "\n",
    "    # log hyper-parameters\n",
    "    run['hyper-parameters'] = PARAMS\n",
    "    run[\"sys/tags\"].add([\"vanilla\", \"val\", \"binary\", \"epochs:300\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3eda9-1b7b-4c8a-81ec-afd854342059",
   "metadata": {},
   "source": [
    "#### load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f107f3d-d9dc-449e-8afb-95c3044e7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179fb226-89f8-4a7c-a7bd-15ed22461ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization for two images\n",
    "\n",
    "def subShow(IMG1, IMG2):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(IMG1, cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(IMG2, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c898a-6ba3-43f6-a2ca-987f65ef8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/bigdata/casus/MLID/RuiLi/Data/LM/zebrafish_partial_15/'\n",
    "\n",
    "Mask = np.load(PATH + 'biMasks15.npy')\n",
    "IMG = np.load(PATH + 'rawGray15.npy')\n",
    "\n",
    "Mask = Mask.reshape(-1, 1040, 1392)  # flatten into images \n",
    "IMG = IMG.reshape(-1, 1040, 1392)\n",
    "\n",
    "Mask = Mask[...,176:(176+Mask.shape[1])]  # crop for later scaling\n",
    "IMG = IMG[...,176:(176+IMG.shape[1])]\n",
    "\n",
    "print('Mask info: ', Mask.shape, Mask.dtype)\n",
    "print('Image info: ', IMG.shape, IMG.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3378f95-f871-4f10-b9fb-90862e9e8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the images\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "SIZE = [256, 256]\n",
    "totalIMG = Mask.shape[0]\n",
    "numIMG = 250\n",
    "\n",
    "smallIMG = resize(IMG[:numIMG,...], (numIMG,SIZE[0],SIZE[1]), anti_aliasing=True)\n",
    "smallIMG = np.interp(smallIMG, (smallIMG.min(), smallIMG.max()), (0, 1))  # rescale the img\n",
    "\n",
    "smallMask = resize(Mask[:numIMG,...].astype(bool), (numIMG,SIZE[0],SIZE[1]), anti_aliasing=False)\n",
    "smallMask = smallMask.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b710b5-3f42-4b3a-ade4-eb9831eed225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "\n",
    "NUM = 100\n",
    "\n",
    "subShow(Mask[NUM,...], IMG[NUM,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a24383-a486-4ab1-8cb2-c735c0344702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patchify the images\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "def rawPatch(imageStack,patchPara):\n",
    "    all_img_patches = []\n",
    "\n",
    "    for img in range(imageStack.shape[0]):\n",
    "        large_image = imageStack[img]\n",
    "\n",
    "        patches_img = patchify(large_image, (patchPara['x'],patchPara['y']), step=patchPara['step'])  # no overlap\n",
    "\n",
    "        for i in range(patches_img.shape[0]):\n",
    "            for j in range(patches_img.shape[1]):\n",
    "\n",
    "                single_patch_img = patches_img[i,j,:,:]\n",
    "                # transform the image if the type is not correct\n",
    "                if single_patch_img.dtype == 'uint8':\n",
    "                    single_patch_img = (single_patch_img.astype('float32')) / 255.  # remember to standarize into 0-1\n",
    "                    \n",
    "                all_img_patches.append(single_patch_img)\n",
    "    \n",
    "    return all_img_patches, patches_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be02f5-300e-4fbe-9456-af190dfd4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for the resized data\n",
    "\n",
    "subShow(smallIMG[0,...], smallMask[0,...])\n",
    "\n",
    "print('img:',smallIMG.shape, smallIMG.dtype)\n",
    "print('mask:',smallMask.shape, smallMask.dtype)\n",
    "\n",
    "print('img range:', np.max(smallIMG), np.min(smallIMG))\n",
    "print('mask range:', np.max(smallMask), np.min(smallMask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df646c-e002-49e5-8a11-d1ebcdbb1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preporcessing the data into patches\n",
    "\n",
    "# train dataset\n",
    "patchPara = {'x': 256, 'y': 256, 'step':256}\n",
    "\n",
    "X_patches, _ =  rawPatch(smallIMG, patchPara); X_patches = np.stack((X_patches,)*3, axis=-1)\n",
    "Y_masks, _ = rawPatch(smallMask, patchPara); Y_masks = np.expand_dims(Y_masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b630187-80a1-4773-80d3-4e2039989308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data properties\n",
    "\n",
    "print('patches shape:',X_patches.shape, X_patches.dtype)\n",
    "print('mask shape:',Y_masks.shape, Y_masks.dtype)\n",
    "print(np.max(Y_masks[0,...]), np.min(Y_masks[0,...]))\n",
    "print(np.max(X_patches[0,...]), np.min(X_patches[0,...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f04c29-51d5-4281-b1af-1cf7ee03d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sanity check for the mask and images\n",
    "\n",
    "startNum = 100\n",
    "n_samples = 4\n",
    "\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(2, n_samples, 1+i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_patches[int(i+startNum)], cmap='gray')\n",
    "    \n",
    "for i in range(n_samples):\n",
    "    plt.subplot(2, n_samples, 1+n_samples+i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(Y_masks[int(i+startNum)], cmap='gray')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c12e3-8637-4663-bed7-07a175396120",
   "metadata": {},
   "source": [
    "#### Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deed7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet structure in blocks\n",
    "import tensorflow.keras as k\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam  # ! notice here must write in tensorflow.keras\n",
    "from keras.layers import Activation, MaxPool2D, Concatenate\n",
    "\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
    "    x = BatchNormalization()(x)   #Not in the original network. \n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)  #Not in the original network\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Encoder block: Conv block followed by maxpooling\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p   \n",
    "\n",
    "#Decoder block\n",
    "#skip features gets input from encoder for concatenation\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "#Build Unet using the blocks\n",
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024) #Bridge\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)  #Binary (can be multiclass)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "model = build_unet(input_shape)\n",
    "model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])  # add Adam from Keras, not tensorflow.adam\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50a2c5-915c-4183-a4bb-e4107c7470e6",
   "metadata": {},
   "source": [
    "#### Realize the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d387d90-81b9-4fee-8811-c9cfcf96fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images = X_patches\n",
    "masks = Y_masks\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(images, masks, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# X_train = Xtrain_patches; Y_train = Ytrain_patches;\n",
    "# X_test = Xtest_patches; Y_test = Ytest_patches;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63343256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "\n",
    "seed=24  # gurantee the images and masks are the same with augmentaion\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# dictionary for augmentation\n",
    "img_data_gen_args = dict(rotation_range=90,\n",
    "                     width_shift_range=0.3,\n",
    "                     height_shift_range=0.3,\n",
    "                     shear_range=0.5,\n",
    "                     zoom_range=0.3,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect')\n",
    "\n",
    "mask_data_gen_args = dict(rotation_range=90,\n",
    "                     width_shift_range=0.3,\n",
    "                     height_shift_range=0.3,\n",
    "                     shear_range=0.5,\n",
    "                     zoom_range=0.3,\n",
    "                     horizontal_flip=True,\n",
    "                     vertical_flip=True,\n",
    "                     fill_mode='reflect',)\n",
    "                     # preprocessing_function = lambda x: np.where(x>0, 1, 0).astype(x.dtype)) \n",
    "#Binarize the output again. Because the new-generated images comes with interperated values\n",
    "\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "\n",
    "\n",
    "batch_size= 8  # 16 will dead\n",
    "\n",
    "# # generator\n",
    "\n",
    "# image_generator = image_data_generator.flow(X_train, augment=False, seed=seed, batch_size=batch_size)\n",
    "# valid_img_generator = image_data_generator.flow(X_val, augment=False, seed=seed, batch_size=batch_size) #Default batch size 32, if not specified here\n",
    "\n",
    "# mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "# mask_generator = mask_data_generator.flow(Y_train, seed=seed, batch_size=batch_size)  # the seed is same\n",
    "# valid_mask_generator = mask_data_generator.flow(Y_val, seed=seed, batch_size=batch_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c40fa-24d8-45fe-b3b3-66e3ce523b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator\n",
    "\n",
    "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
    "image_data_generator.fit(X_train, augment=True, seed=seed)  # relevant to normalization\n",
    "\n",
    "image_generator = image_data_generator.flow(X_train, seed=seed)\n",
    "valid_img_generator = image_data_generator.flow(X_val, seed=seed)\n",
    "\n",
    "mask_data_generator = ImageDataGenerator(**mask_data_gen_args)\n",
    "mask_data_generator.fit(Y_train, augment=True, seed=seed)\n",
    "mask_generator = mask_data_generator.flow(Y_train, seed=seed)\n",
    "valid_mask_generator = mask_data_generator.flow(Y_val, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c7de1-91b7-4bab-8be6-5cf74de85512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack the two generators together\n",
    "\n",
    "def my_image_mask_generator(image_generator, mask_generator):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in train_generator:\n",
    "        yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "\n",
    "my_generator = my_image_mask_generator(image_generator, mask_generator)  # give out the image generator and mask at teh same time\n",
    "\n",
    "validation_datagen = my_image_mask_generator(valid_img_generator, valid_mask_generator)\n",
    "\n",
    "x = image_generator.next()\n",
    "y = mask_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645621ad-9e38-4d73-bd25-9b5e4d7ff2d7",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca5025-6f7b-4d9b-87e4-de7cc670ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as k\n",
    "\n",
    "if DOCUMENT:\n",
    "    callbacks = [\n",
    "        # k.callbacks.EarlyStopping(patience=15, monitor='val_loss'),\n",
    "        neptune_cbk, \n",
    "        k.callbacks.TensorBoard(log_dir = './Unet/tensorBoard')  # save in new folder in hemera. Also update in neptune\n",
    "    ]\n",
    "else:\n",
    "    callbacks = [\n",
    "        # k.callbacks.EarlyStopping(patience=15, monitor='val_loss'),\n",
    "        k.callbacks.TensorBoard(log_dir = './Unet/tensorBoard')  # save in new folder in hemera. Also update in neptune\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191b3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the hyper param\n",
    "\n",
    "import tensorflow.keras as k\n",
    "steps_per_epoch = 3*(len(X_train))//batch_size  # depend on the training dataset\n",
    "\n",
    "# callbacks = [\n",
    "#     #k.callbacks.EarlyStopping(patience=10, monitor='val_loss'),\n",
    "#     neptune_cbk,\n",
    "#     k.callbacks.TensorBoard(log_dir = 'logsAugH')\n",
    "# ]\n",
    "\n",
    "history = model.fit_generator(my_generator, validation_data=validation_datagen, \n",
    "                    steps_per_epoch=steps_per_epoch, \n",
    "                    validation_steps=steps_per_epoch, epochs=TRAIN, callbacks=callbacks)  # use the model from blocks build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa4975-5502-43ee-9fda-8ab223e6871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as local\n",
    "\n",
    "model.save(\"./Unet/model/Unet2D_vanilla_noAug_pad.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efd04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy and loss of the training\n",
    "\n",
    "# loss \n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# # accuracy\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IOU on test dataset\n",
    "\n",
    "# y_pred=model.predict(X_test)\n",
    "# y_pred_thresholded = y_pred > 0.5\n",
    "\n",
    "# intersection = np.logical_and(Y_test, y_pred_thresholded)\n",
    "# union = np.logical_or(Y_test, y_pred_thresholded)\n",
    "# iou_score = np.sum(intersection) / np.sum(union)\n",
    "# print(\"IoU socre is: \", iou_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c5b75a-c594-409a-bbae-859b4c163e06",
   "metadata": {},
   "source": [
    "#### test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c04d7e-6b75-4336-9a42-07460192d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # running test directly from loading the model\n",
    "\n",
    "# from patchify import patchify, unpatchify\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import ndimage\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import random\n",
    "\n",
    "\n",
    "# import tensorflow\n",
    "# import tensorflow.keras\n",
    "\n",
    "# import segmentation_models as sm\n",
    "\n",
    "\n",
    "# # loading model from local way\n",
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model(\"./Unet/model/Unet2D_vanilla_noAug_pad.h5\", compile=False)  # some self-defined loss should be loaded by segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ae657-e1fd-4c83-bd4a-61b754ecab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the test datasset for the rest of the images\n",
    "\n",
    "testIMG = IMG[numIMG:totalIMG,...]\n",
    "testMask = Mask[numIMG:totalIMG,...]\n",
    "\n",
    "testIMG = testIMG[...,:testIMG.shape[1]]  # crop for later scaling\n",
    "testMask = testMask[...,:testMask.shape[1]]\n",
    "\n",
    "print(testIMG.shape)\n",
    "\n",
    "# pre-process the dataset\n",
    "\n",
    "X_test = resize(testIMG, (totalIMG - numIMG,SIZE[0],SIZE[1]), anti_aliasing=True)  # resize the images\n",
    "X_test = np.interp(X_test, (X_test.min(), X_test.max()), (0, 1))\n",
    "\n",
    "Y_test = resize(testMask.astype(bool), (totalIMG - numIMG,SIZE[0],SIZE[1]), anti_aliasing=False)\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "print('before:',testIMG.shape)\n",
    "print('after:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4dfe64-c3f7-4a25-b956-e37789eebd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the images\n",
    "\n",
    "patchPara = {'x': 256, 'y': 256, 'step':256}\n",
    "\n",
    "X_test, _ =  rawPatch(X_test, patchPara); X_test = np.stack((X_test,)*3, axis=-1)\n",
    "Y_test, _ = rawPatch(Y_test, patchPara); Y_test = np.expand_dims(Y_test, -1)\n",
    "\n",
    "print('test image shape:', X_test.shape, X_test.dtype)\n",
    "print('test image shape:', Y_test.shape, Y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1a6f2-bf2c-43e9-9579-c88eaab6310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction \n",
    "\n",
    "imgPred = model.predict(X_test)\n",
    "\n",
    "# print(imgPred.shape, Y_test.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d10d3-ba0e-42c7-be6e-68b382ebf94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the data range\n",
    "\n",
    "print(np.max(X_test), np.min(X_test))\n",
    "print(np.max(Y_test), np.min(Y_test))\n",
    "print(np.max(imgPred), np.min(imgPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3010e-58d8-4299-820c-28d4d89f54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check \n",
    "\n",
    "NUM = 16\n",
    "\n",
    "subShow(imgPred[NUM,...], Y_test[NUM,...])  # they are binary value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b853ede-e2af-4934-a4d7-538799056106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # without docuent\n",
    "\n",
    "# imagePred = []\n",
    "\n",
    "# for i in range(imgPred.shape[0]):\n",
    "#     tIMG = X_test[i,...][...,0]  # input\n",
    "#     tPred = imgPred[i,...] # prediction\n",
    "#     tMask = Y_test[i,...] # GT\n",
    "    \n",
    "#     bar = np.ones((tIMG.shape[0], 15))   # lines\n",
    "#     combTemp = np.concatenate((tIMG, bar, np.squeeze(tPred), bar, np.squeeze(tMask)), axis=1)\n",
    "    \n",
    "#     imagePred.append(combTemp)\n",
    "    \n",
    "# imagePred = np.asarray(imagePred)\n",
    "\n",
    "# # sanity check for one image\n",
    "# test = np.asarray(imagePred)\n",
    "# plt.imshow(test[0,...], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ffb9fa-f118-4af3-8dde-e087a0282d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# document with neptune\n",
    "\n",
    "imagePred = []\n",
    "\n",
    "for i in range(imgPred.shape[0]):\n",
    "    tIMG = X_test[i,...][...,0]  # input\n",
    "    tPred = imgPred[i,...] # prediction\n",
    "    tMask = Y_test[i,...] # GT\n",
    "    \n",
    "    bar = np.ones((tIMG.shape[0], 15))   # lines\n",
    "    combTemp = np.concatenate((tIMG, bar, np.squeeze(tPred), bar, np.squeeze(tMask)), axis=1)\n",
    "    \n",
    "    \n",
    "    # upload the test images to neptune\n",
    "    if DOCUMENT:\n",
    "        # upload the test results into neptune with handle 'description'\n",
    "        run[\"test/sample_images\"].log(neptune.types.File.as_image(combTemp), name=str(i), description='test images')  \n",
    "    \n",
    "    imagePred.append(combTemp)\n",
    "    \n",
    "imagePred = np.asarray(imagePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f146162-46f1-4df4-9a5b-2c2a94fae521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "\n",
    "print(imagePred.shape)\n",
    "plt.imshow(imagePred[1,...], cmap='gray')\n",
    "\n",
    "print(np.max(imagePred), np.min(imagePred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a3fc9-f820-4ac3-b1dd-0f21fc8ba193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the neptune\n",
    "if DOCUMENT:\n",
    "    run.stop() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA (LM)",
   "language": "python",
   "name": "n2v-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
